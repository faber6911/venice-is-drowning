{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "tLX17sFpCqZ6",
    "outputId": "2c5a0720-c62d-492a-fc33-ccee07fefe66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 25 09:40:08 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K20Xm         On   | 00000000:08:00.0 Off |                    0 |\r\n",
      "| N/A   47C    P0    57W / 235W |   5485MiB /  5700MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla K20Xm         On   | 00000000:84:00.0 Off |                    0 |\r\n",
      "| N/A   52C    P0    56W / 235W |   5485MiB /  5700MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "go = False\n",
    "if go:\n",
    "    \n",
    "    import os\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "    import tensorflow as tf\n",
    "    from keras import backend as K\n",
    "\n",
    "    set_gpu=True\n",
    "\n",
    "    if set_gpu:\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";  # The GPU id to use, usually either \"0\" or \"1\";\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  # Do other imports now...\n",
    "        print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "\n",
    "        num_cores = 39\n",
    "\n",
    "        GPU=True\n",
    "        CPU=False\n",
    "\n",
    "        if GPU:\n",
    "            num_GPU = 1\n",
    "            num_CPU = 1\n",
    "        if CPU:\n",
    "            num_CPU = 1\n",
    "            num_GPU = 0\n",
    "\n",
    "        config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
    "                                inter_op_parallelism_threads=num_cores, \n",
    "                                allow_soft_placement=True,\n",
    "                                device_count = {'CPU' : num_CPU,\n",
    "                                                'GPU' : num_GPU}\n",
    "                               )\n",
    "\n",
    "        session = tf.Session(config=config)\n",
    "        K.set_session(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "VYyvPbEZ7sCY",
    "outputId": "081dc96e-0f2a-4345-b237-9ed7ce7c8b3e"
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/DBertazioli/host/master/datas/df_final_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "14JMWnZb8Ead",
    "outputId": "31cd36c0-bc29-4c73-e0bc-0af9cad920dc"
   },
   "outputs": [],
   "source": [
    "#!pip install pyforest\n",
    "#from pyforest import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.192241</td>\n",
       "      <td>0.111166</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>-0.012548</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>-0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.097356</td>\n",
       "      <td>0.057627</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.072702</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.005893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.021915</td>\n",
       "      <td>-0.011354</td>\n",
       "      <td>-0.020139</td>\n",
       "      <td>0.020487</td>\n",
       "      <td>0.107396</td>\n",
       "      <td>0.010978</td>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.019311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.135697</td>\n",
       "      <td>-0.077292</td>\n",
       "      <td>-0.034058</td>\n",
       "      <td>0.030868</td>\n",
       "      <td>0.134730</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.031421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.215488</td>\n",
       "      <td>-0.122519</td>\n",
       "      <td>-0.039756</td>\n",
       "      <td>0.032934</td>\n",
       "      <td>0.152834</td>\n",
       "      <td>0.029876</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.041401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1        V2        V3        V4        V5        V6        V7        V8  \\\n",
       "1   1  0.192241  0.111166  0.017747 -0.012548  0.033027 -0.010471  0.014676   \n",
       "2   2  0.097356  0.057627 -0.001360  0.004587  0.072702  0.000261  0.014648   \n",
       "3   3 -0.021915 -0.011354 -0.020139  0.020487  0.107396  0.010978  0.014621   \n",
       "4   4 -0.135697 -0.077292 -0.034058  0.030868  0.134730  0.021047  0.014593   \n",
       "5   5 -0.215488 -0.122519 -0.039756  0.032934  0.152834  0.029876  0.014565   \n",
       "\n",
       "         V9  \n",
       "1 -0.007925  \n",
       "2  0.005893  \n",
       "3  0.019311  \n",
       "4  0.031421  \n",
       "5  0.041401  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_harmonics = pd.read_csv(\"../data/output/harmonics.csv\", index_col=0)\n",
    "df_harmonics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "14JMWnZb8Ead",
    "outputId": "31cd36c0-bc29-4c73-e0bc-0af9cad920dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78888, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/df_final_processed.csv\", index_col = 0)\n",
    "df.head()\n",
    "\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "#some zeroes\n",
    "#series = df.level_scaled.values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler(feature_range=(0.01, 1))\n",
    "\n",
    "series = sc.fit_transform(df.level.values.reshape(-1, 1))\n",
    "\n",
    "split_index = -7*24\n",
    "\n",
    "#test_series = series [split_index:]\n",
    "#series = series [:split_index]\n",
    "#series = series.reshape((len(series), n_features))\n",
    "#test_series = test_series.reshape((len(test_series), n_features))\n",
    "\n",
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_harmonics_list = []\n",
    "harmonics_list = []\n",
    "for col in df_harmonics.columns[1:]:\n",
    "    #print(col)\n",
    "    sc_harm = MinMaxScaler()\n",
    "    harmonics_list.append(sc_harm.fit_transform(df_harmonics[col].values.reshape(-1, 1)))\n",
    "    sc_harmonics_list.append(sc_harm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_rain = MinMaxScaler()\n",
    "rain = sc_rain.fit_transform(df.rain.values.reshape(-1, 1))\n",
    "\n",
    "sc_wind = MinMaxScaler()\n",
    "vel_wind = sc_wind.fit_transform(df.vel_wind.values.reshape(-1, 1))\n",
    "\n",
    "sc_dir_wind = MinMaxScaler()\n",
    "dir_wind = sc_dir_wind.fit_transform(df.dir_wind.values.reshape(-1, 1))\n",
    "\n",
    "sc_lunar = MinMaxScaler()\n",
    "lunar = sc_lunar.fit_transform(df.inv_dist.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harmonics_list.extend([series, rain, vel_wind, dir_wind])\n",
    "\n",
    "len(harmonics_list),#harmonics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78888, 12)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_series = np.hstack(harmonics_list)\n",
    "input_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24h ahead single preds\n",
    "steps_ahead = 168-1\n",
    "padded_series = np.expand_dims(np.concatenate([series.flatten(), np.zeros(steps_ahead)]), axis = -1)\n",
    "padded_series\n",
    "\n",
    "target_series = np.roll(padded_series, -steps_ahead)[:series.shape[0]] #need to discard the last as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78721, 1), (78721, 1), (78721, 12))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_series = target_series[:-steps_ahead]  #removing the zero padding\n",
    "series = series[:-steps_ahead] #removing the zero padding\n",
    "input_series = input_series[:-steps_ahead]\n",
    "series.shape, target_series.shape, input_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, CuDNNLSTM, LeakyReLU, Dropout, BatchNormalization\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "\n",
    "# define model\n",
    "def make_model(n_input, n_features, \n",
    "               verbose = False, multi = True, use_CuDNNLSTM = True,\n",
    "              loss = \"mse\", metrics = [\"mae\", \"mape\"], opt = \"adam\",\n",
    "              lr = 0.001, batch_size = 512, reg = True):\n",
    "    K.clear_session()\n",
    "    LSTM_layer = LSTM if not use_CuDNNLSTM else CuDNNLSTM\n",
    "    if opt == \"adam\":\n",
    "        opt = Adam (lr = lr )\n",
    "    else:\n",
    "        opt = opt\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM_layer(512, input_shape=(n_input, n_features), return_sequences=True))\n",
    "    if reg:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    if reg:\n",
    "        model.add(Dropout(rate = 0.5))\n",
    "    for i in range(0):\n",
    "        model.add(LSTM_layer(512, return_sequences=True))\n",
    "        if reg:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        if reg:\n",
    "            model.add(Dropout( rate = 0.3))\n",
    "    \n",
    "    for i in range(1):\n",
    "        model.add(LSTM_layer(256, return_sequences = False))\n",
    "        if reg:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        if reg:\n",
    "            model.add(Dropout(rate = 0.4))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU())\n",
    "    if reg:\n",
    "        model.add(Dropout(rate = 0.3))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=loss, metrics = metrics)\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    if multi:\n",
    "        mmodel = multi_gpu_model(model, 2)\n",
    "        mmodel.compile(optimizer=opt, loss=loss, metrics = metrics)\n",
    "        return mmodel, model\n",
    "    else: \n",
    "        \n",
    "        return None, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 1*12\n",
    "\n",
    "train_generator = TimeseriesGenerator(input_series, target_series, start_index=0, end_index=len(series) + split_index-1, length=n_input, batch_size=1)\n",
    "#val_generator = TimeseriesGenerator(series, target_series, start_index=len(series) + 2*split_index-n_input, end_index=len(series)+split_index-1, length=n_input, batch_size=1)\n",
    "test_generator = TimeseriesGenerator(input_series, target_series, start_index=len(series) + split_index -n_input, end_index=len(series)-1, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78541, 168)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator), len(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78541, 12, 12), (78541, 1))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "for train,test in train_generator:\n",
    "    train_list.append(train)\n",
    "    test_list.append(test)\n",
    "train_input = np.concatenate(train_list, axis = 0)\n",
    "train_targets = np.concatenate(test_list, axis = 0)\n",
    "train_input.shape, train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((168, 12, 12), (168, 1))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "for train, test in test_generator: #some weird but with the last access\n",
    "    train_list.append(train)\n",
    "    test_list.append(test)\n",
    "\n",
    "    \n",
    "test_input = np.concatenate(train_list, axis = 0)\n",
    "test_targets = np.concatenate(test_list, axis = 0)\n",
    "test_input.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/dbertazioli/venice_is_drowing\" target=\"_blank\">https://app.wandb.ai/dbertazioli/venice_is_drowing</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/dbertazioli/venice_is_drowing/runs/4y8248c0\" target=\"_blank\">https://app.wandb.ai/dbertazioli/venice_is_drowing/runs/4y8248c0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "from wandb.keras import WandbCallback as wb\n",
    "\n",
    "wandb.init(project = \"venice_is_drowing\", name = f\"lstm_single_output_test_168h_{n_input}_input_{input_series.shape[1]}_feat\")\n",
    "cfg = wandb.config\n",
    "batch_size = 512\n",
    "cfg.batch_size = batch_size\n",
    "cfg.n_features = n_features\n",
    "cfg.n_input = n_input\n",
    "cfg.epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 12, 512)           1077248   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 512)           2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 12, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 512)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 256)               788480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,901,825\n",
      "Trainable params: 1,900,289\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mmodel, model = make_model(n_input, input_series.shape[1], opt = \"adam\", lr = 0.001, reg = True, \n",
    "                           multi = True, use_CuDNNLSTM = True, verbose = True,\n",
    "                           loss = \"mape\", metrics = [\"mse\",\"mae\", \"mape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78541 samples, validate on 168 samples\n",
      "Epoch 1/250\n",
      "\r",
      "  512/78541 [..............................] - ETA: 7s - loss: 16.1357 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0783 - mean_absolute_percentage_error: 16.1357"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2048/78541 [..............................] - ETA: 1:12 - loss: 18.7315 - mean_squared_error: 0.0113 - mean_absolute_error: 0.0858 - mean_absolute_percentage_error: 18.7315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newuser/.local/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.698995). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/home/newuser/.local/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.850842). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-353e8e52c7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     callbacks=[plot_losses, \n\u001b[1;32m     23\u001b[0m               \u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m               \u001b[0mwb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m               ]\n\u001b[1;32m     26\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/intel/intelpython3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from myutils import TrainingPlot\n",
    "\n",
    "\n",
    "plot_losses = TrainingPlot()\n",
    "es = EarlyStopping(monitor = \"val_loss\", patience = 50, restore_best_weights = True, verbose = 1)\n",
    "rl = ReduceLROnPlateau(monitor = \"val_loss\", patience = 25, cooldown=10, factor=0.5, verbose = 1)\n",
    "\n",
    "# fit model\n",
    "history = mmodel.fit(\n",
    "    train_input, train_targets,\n",
    "    epochs=cfg.epochs,\n",
    "    batch_size = cfg.batch_size, \n",
    "    \n",
    "    verbose=1, \n",
    "    shuffle = False,\n",
    "    \n",
    "    #validation_data=ttest_generator, \n",
    "    #validation_steps = 6,\n",
    "    validation_data = (test_input, test_targets),\n",
    "    \n",
    "    callbacks=[plot_losses, \n",
    "              es, rl,\n",
    "              wb(log_gradients=False, log_weights=False)\n",
    "              ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.123519443330311,\n",
       " 0.0013734966383448669,\n",
       " 0.030145931988954544,\n",
       " 9.123519443330311]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.12351936734321\n",
      "9.03350650272615\n"
     ]
    }
   ],
   "source": [
    "def calc_mape(real, pred):\n",
    "    return (100*np.abs(real-pred)/real/real.shape[0]).sum()\n",
    "print(calc_mape(real_data, real_preds)) #mape on real-data preds\n",
    "#print(calc_mape(real_data, preds)) #mape on iterated preds #not really makes sense with 168 steps ahead\n",
    "print(calc_mape(real_data[0:1], real_preds[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.235714803065974, 10.860282897949205)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "rmse_real_preds = sqrt(mean_squared_error(sc.inverse_transform(real_preds.reshape(-1, 1)), sc.inverse_transform(real_data.reshape(-1, 1))))\n",
    "#rmse_preds = sqrt(mean_squared_error(sc.inverse_transform(preds1.reshape(-1, 1)), sc.inverse_transform(real_data.reshape(-1, 1))))\n",
    "rmse_single_pred = sqrt(mean_squared_error(sc.inverse_transform(real_data[0:1].reshape(-1, 1)), sc.inverse_transform(real_preds[0:1].reshape(-1, 1))))\n",
    "\n",
    "rmse_real_preds,  rmse_single_pred"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "venice_lstm_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
